{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0ca8ba-d913-45a6-a1ca-82a6bff8d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Any\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09c899b-f994-41df-97be-54af973c7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/'\n",
    "LOAD_MODEL = 'effnetb3_600_fold1_epoch1'\n",
    "\n",
    "IMAGE_SIZE = 600\n",
    "BATCH_SIZE = 48\n",
    "NUM_WORKERS = 4\n",
    "USE_AMP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69705b-c586-4808-a152-f94863ca5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, csv, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        image = cv2.imread(row.filepath)[:,:,::-1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=image)\n",
    "            image = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        \n",
    "        return torch.tensor(image)\n",
    "\n",
    "\n",
    "transforms = albumentations.Compose([\n",
    "    albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    albumentations.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d592ec-3a42-49c0-acd4-7b0801807aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_module(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "\n",
    "class DenseCrossEntropy(nn.Module):\n",
    "    def forward(self, x, target):\n",
    "        x = x.float()\n",
    "        target = target.float()\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "\n",
    "        loss = -logprobs * target\n",
    "        loss = loss.sum(-1)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=3):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
    "        self.reset_parameters()\n",
    "        self.k = k\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
    "        cosine, _ = torch.max(cosine_all, dim=2)\n",
    "        return cosine   \n",
    "\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "        super(GeM,self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1)*p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "\n",
    "class EffnetB3_Landmark(nn.Module):\n",
    "\n",
    "    def __init__(self, out_dim, load_pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model('tf_efficientnet_b3_ns', pretrained=False)\n",
    "        self.feat = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features, 512, bias=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            Swish_module()\n",
    "        )\n",
    "        self.backbone.global_pool = GeM()\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # self.swish = Swish_module()\n",
    "        self.metric_classify = ArcMarginProduct_subcenter(512, out_dim)\n",
    "\n",
    "\n",
    "    def extract(self, x):\n",
    "        return self.backbone(x)[:, :, 0, 0]\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)\n",
    "        # logits_m = self.metric_classify(self.feat(x))\n",
    "        # return logits_m\n",
    "        return self.feat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38e724-5c19-45c8-ae5a-65875a9bf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dim = 81313\n",
    "\n",
    "load = torch.load('./model_checkpoints/{}.pth'.format(LOAD_MODEL))\n",
    "model_only_weight = {k[7:] if k.startswith('module.') else k: v for k, v in load['model_state_dict'].items()}\n",
    "\n",
    "model = EffnetB3_Landmark(out_dim=out_dim).cuda()\n",
    "model.load_state_dict(model_only_weight)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76662800-0e82-413a-98d0-60d191c8474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "# df = pd.read_csv('../input/train.csv')\n",
    "tmp = np.sqrt(1 / np.sqrt(df['landmark_id'].value_counts().sort_index().values))\n",
    "margins = (tmp - tmp.min()) / (tmp.max() - tmp.min()) * 0.45 + 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa08eed5-9c01-4ca9-917d-96e8dd77c8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33721154991697344"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b447fd5-d9be-4acf-b45b-4baf12d596a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3342744605698179"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a95aa188-fd81-41de-a8a8-559385bd3a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8408964152537145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-9ffd70a054b1>:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  (tmp - tmp.min()) / (tmp.max() - tmp.min()) * 0.45 + 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.sqrt(1 / np.sqrt(2))\n",
    "print(tmp)\n",
    "(tmp - tmp.min()) / (tmp.max() - tmp.min()) * 0.45 + 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86af8fc-589b-44de-ad47-820ccd20a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "df = pd.read_csv('../input/train_full.csv')\n",
    "df['filepath'] = df['id'].apply(lambda x: os.path.join(DATA_DIR, 'gldv2_full', x[0], x[1], x[2], f'{x}.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aca5728-5f2c-4331-9199-5c4ccaa1d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = pd.read_csv('../input/train.csv')\n",
    "lm_set = set(df_small['landmark_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1509d68-f163-436e-a412-be35b1a3617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_landmark'] = df['landmark_id'].apply(lambda x: x in lm_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a9d9d2-eef8-4180-84db-276715fc9f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['url', 'filepath'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be18a927-284d-45e5-b3f7-49694ce8e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['filtered_landmark'] == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07111fe7-5d3c-47ce-9108-93a6ae79236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../input/train_full_filtered_withLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac50abd4-f292-4a1d-b6b5-cd8074aa6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/recognition_solution_v2.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8416d550-df00-477d-80d5-a0733a878a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['landmarks'].isna()].copy(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2f19465-e34a-45ac-a91e-1da025dc5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../input/nonLandmarks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec31cd-5bf6-488d-ac8e-007eb08f5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "df = pd.read_csv('../input/train_full.csv')\n",
    "df['filepath'] = df['id'].apply(lambda x: os.path.join(DATA_DIR, 'gldv2_full', x[0], x[1], x[2], f'{x}.jpg'))\n",
    "\n",
    "dataset = LandmarkDataset(df, transform=transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8999f035-71d7-4e02-a1c7-78bb31f21b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe\n",
    "df = pd.read_csv('../input/recognition_solution_v2.1.csv')\n",
    "# df['filepath'] = df['id'].apply(lambda x: os.path.join(DATA_DIR, 'test_2019', x[0], x[1], x[2], f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d901b197-a2d6-4644-acc2-745fcb2bcb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117577, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80edf93-b6fe-471d-996c-4eb4178b0ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117577/117577 [00:00<00:00, 205144.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(df.shape[0])):\n",
    "    assert os.path.exists(df['filepath'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f96884fe-fb2d-4d44-a342-78d3187f4738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117577, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d2ef3da-7985-4877-a4ff-4bb3a3fbfbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115605, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['landmarks'].isna()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae40031-5bde-454b-9b75-d5a84f7cd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filepath'] = df['id'].apply(lambda x: os.path.join(DATA_DIR, 'test_2019', x[0], x[1], x[2], f'{x}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "974a641d-ba5f-48f9-a402-574923613181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>Usage</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e324e0f3e6d9e504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/e/3/2/e324e0f3e6d9e504.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9e17c5f3e0c47b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/d/9/e/d9e17c5f3e0c47b3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a748a755ed67512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>../input/test_2019/1/a/7/1a748a755ed67512.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>537bf9bdfccdafea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/5/3/7/537bf9bdfccdafea.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13f4c974274ee08b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/1/3/f/13f4c974274ee08b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117571</th>\n",
       "      <td>a339ef58d82dcb86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/a/3/3/a339ef58d82dcb86.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117573</th>\n",
       "      <td>5426472625271a4d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>../input/test_2019/5/4/2/5426472625271a4d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117574</th>\n",
       "      <td>7b6a585405978398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>../input/test_2019/7/b/6/7b6a585405978398.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117575</th>\n",
       "      <td>d885235ba249cf5d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>../input/test_2019/d/8/8/d885235ba249cf5d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117576</th>\n",
       "      <td>c7f657e8d0f7fafb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>../input/test_2019/c/7/f/c7f657e8d0f7fafb.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115605 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id landmarks    Usage  \\\n",
       "0       e324e0f3e6d9e504       NaN  Private   \n",
       "1       d9e17c5f3e0c47b3       NaN  Private   \n",
       "2       1a748a755ed67512       NaN   Public   \n",
       "3       537bf9bdfccdafea       NaN  Private   \n",
       "4       13f4c974274ee08b       NaN  Private   \n",
       "...                  ...       ...      ...   \n",
       "117571  a339ef58d82dcb86       NaN  Private   \n",
       "117573  5426472625271a4d       NaN   Public   \n",
       "117574  7b6a585405978398       NaN   Public   \n",
       "117575  d885235ba249cf5d       NaN   Public   \n",
       "117576  c7f657e8d0f7fafb       NaN  Private   \n",
       "\n",
       "                                             filepath  \n",
       "0       ../input/test_2019/e/3/2/e324e0f3e6d9e504.jpg  \n",
       "1       ../input/test_2019/d/9/e/d9e17c5f3e0c47b3.jpg  \n",
       "2       ../input/test_2019/1/a/7/1a748a755ed67512.jpg  \n",
       "3       ../input/test_2019/5/3/7/537bf9bdfccdafea.jpg  \n",
       "4       ../input/test_2019/1/3/f/13f4c974274ee08b.jpg  \n",
       "...                                               ...  \n",
       "117571  ../input/test_2019/a/3/3/a339ef58d82dcb86.jpg  \n",
       "117573  ../input/test_2019/5/4/2/5426472625271a4d.jpg  \n",
       "117574  ../input/test_2019/7/b/6/7b6a585405978398.jpg  \n",
       "117575  ../input/test_2019/d/8/8/d885235ba249cf5d.jpg  \n",
       "117576  ../input/test_2019/c/7/f/c7f657e8d0f7fafb.jpg  \n",
       "\n",
       "[115605 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b40235b-0dac-4ad5-9d62-6676aa691c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    embeddings = np.zeros((len(df) , 512), dtype=np.float16)\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        \n",
    "        data = data.cuda()\n",
    "\n",
    "        with autocast():\n",
    "            embedding = model(data)\n",
    "        \n",
    "        #break\n",
    "        embeddings[idx*BATCH_SIZE:idx*BATCH_SIZE+embedding.size(0), :] = embedding.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14475050-d198-4ddc-90d5-fb56c0f58f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((100000 , 512), dtype=np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d090a81-2cc1-42f1-8dff-83bc19a80571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(\"./embeddings/{}_embeddings\".format(LOAD_MODEL), embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
