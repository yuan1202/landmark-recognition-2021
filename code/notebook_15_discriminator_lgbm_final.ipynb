{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0ca8ba-d913-45a6-a1ca-82a6bff8d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used memory: 4.27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Any\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import timm\n",
    "\n",
    "import psutil\n",
    "def get_used_memory():\n",
    "    return psutil.Process(os.getpid()).memory_info().vms/1024**3\n",
    "def get_used_memory_txt():\n",
    "    return 'Used memory: {:.2f}'.format(get_used_memory())\n",
    "initial_used_memory=get_used_memory()\n",
    "print(get_used_memory_txt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "272e630f-9b43-4739-aff4-66d019366406",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')\n",
    "df_full = pd.read_csv('../input/train_full.csv')\n",
    "df_lm = df_full[df_full['landmark_id'].isin(df['landmark_id'].unique())].reset_index(drop=True)\n",
    "df_lm.drop(columns='url', inplace=True)\n",
    "lm_img2embd_map = defaultdict(lambda: -1)\n",
    "lm_img2embd_map.update({img_id: i for i, img_id in enumerate(df_lm['id'])})\n",
    "lm_id2class_map = {id_: i for i, id_ in enumerate(sorted(df_lm['landmark_id'].unique()))}\n",
    "df_lm['class'] = df_lm['landmark_id'].map(lambda x: lm_id2class_map[x])\n",
    "lm_img2cls_map = defaultdict(lambda: -1)\n",
    "lm_img2cls_map.update({img: c for img, c in zip(df_lm['id'], df_lm['class'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "576a22cd-52aa-4c3d-b3d4-3fc0a6d69081",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlm = pd.read_csv('../input/recognition_solution_v2.1.csv')\n",
    "df_nlm = df_nlm[df_nlm['landmarks'].isna()].reset_index(drop=True)\n",
    "nlm_img2embd_map = defaultdict(lambda: -1)\n",
    "nlm_img2embd_map.update({img_id: i for i, img_id in enumerate(df_nlm['id'])})\n",
    "nlm_img2cls_map = defaultdict(lambda: -1)\n",
    "nlm_img2cls_map.update({img: 81313 for img in df_nlm['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d29171c-da69-4d9d-ad86-d437dcc1a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, df_full, df_lm, df_nlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399f7353-aa98-44d5-b984-d087f9dd13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./final/VD_dataframe_withFolds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb74573-a8bb-4277-aa04-abb35cd34651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9701120, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81143255-d60c-41f9-a4c6-044312db20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_std = np.load('./final/3.2m_train_landmarks_ensembled_f16_pca.npy')\n",
    "embedding_dba = np.load('./final/3.2m_train_landmarks_ensembled_f16_pca_dba.npy')\n",
    "embedding_npm = np.load('./final/115k_non_landmarks_ensembled_f16_pca.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb8cc4d-7b30-4c61-88d9-b79b1470ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0\n",
    "\n",
    "trn_idx = df_train.loc[df_train['fold'] != FOLD].index.values\n",
    "vld_idx = df_train.loc[df_train['fold'] == FOLD].index.values\n",
    "\n",
    "trn_array = np.zeros((len(trn_idx), 512*4), dtype=np.float32)\n",
    "trn_label = df_train['target'].iloc[trn_idx].values\n",
    "\n",
    "vld_array = np.zeros((len(vld_idx), 512*4), dtype=np.float32)\n",
    "vld_label = df_train['target'].iloc[vld_idx].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99edaa7a-500d-409a-b86c-99bfb4e6b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8731008 [00:00<?, ?it/s]<ipython-input-10-54bbf36555dc>:22: RuntimeWarning: overflow encountered in true_divide\n",
      "  trn_array[i, 1536:] = np.nan_to_num(embd1/embd0)\n",
      "100%|██████████| 8731008/8731008 [09:24<00:00, 15455.33it/s]\n",
      "  0%|          | 0/970112 [00:00<?, ?it/s]<ipython-input-10-54bbf36555dc>:45: RuntimeWarning: overflow encountered in true_divide\n",
      "  vld_array[i, 1536:] = np.nan_to_num(embd1/embd0)\n",
      "100%|██████████| 970112/970112 [01:03<00:00, 15245.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, idx in tqdm(enumerate(trn_idx), total=len(trn_idx)):\n",
    "    \n",
    "    embd0_idx = lm_img2embd_map[df_train['img_id'].iloc[idx]]\n",
    "    if embd0_idx == -1:\n",
    "        embd0_idx = nlm_img2embd_map[df_train['img_id'].iloc[idx]]\n",
    "        embd0 = embedding_npm[embd0_idx]\n",
    "    else:\n",
    "        embd0 = embedding_std[embd0_idx]\n",
    "        \n",
    "    embd1_idx = lm_img2embd_map[df_train['img_id_crossed'].iloc[idx]]\n",
    "    if embd1_idx == -1:\n",
    "        embd1_idx = nlm_img2embd_map[df_train['img_id_crossed'].iloc[idx]]\n",
    "        embd1 = embedding_npm[embd1_idx]\n",
    "    else:\n",
    "        embd1 = embedding_dba[embd1_idx]\n",
    "        \n",
    "    trn_array[i, :512] = embd0\n",
    "    trn_array[i, 512:1024] = embd1\n",
    "    trn_array[i, 1024:1536] = np.nan_to_num(embd1 - embd0)\n",
    "    embd0[embd0 == 0] = .001\n",
    "    embd1[embd1 == 0] = .001\n",
    "    trn_array[i, 1536:] = np.nan_to_num(embd1/embd0)\n",
    "    \n",
    "for i, idx in tqdm(enumerate(vld_idx), total=len(vld_idx)):\n",
    "    \n",
    "    embd0_idx = lm_img2embd_map[df_train['img_id'].iloc[idx]]\n",
    "    if embd0_idx == -1:\n",
    "        embd0_idx = nlm_img2embd_map[df_train['img_id'].iloc[idx]]\n",
    "        embd0 = embedding_npm[embd0_idx]\n",
    "    else:\n",
    "        embd0 = embedding_std[embd0_idx]\n",
    "        \n",
    "    embd1_idx = lm_img2embd_map[df_train['img_id_crossed'].iloc[idx]]\n",
    "    if embd1_idx == -1:\n",
    "        embd1_idx = nlm_img2embd_map[df_train['img_id_crossed'].iloc[idx]]\n",
    "        embd1 = embedding_npm[embd1_idx]\n",
    "    else:\n",
    "        embd1 = embedding_dba[embd1_idx]\n",
    "        \n",
    "    vld_array[i, :512] = embd0\n",
    "    vld_array[i, 512:1024] = embd1\n",
    "    vld_array[i, 1024:1536] = np.nan_to_num(embd1 - embd0)\n",
    "    embd0[embd0 == 0] = .001\n",
    "    embd1[embd1 == 0] = .001\n",
    "    vld_array[i, 1536:] = np.nan_to_num(embd1/embd0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f0e330-6ccc-4d0f-b525-34ad53378b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del embedding_std, embedding_dba, embedding_npm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92a0a4e-8b8b-4325-bfad-7027162416be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(objective='binary', learning_rate=0.01, n_estimators=12000, max_depth=8, n_jobs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c72606-6016-47d7-83a3-0e2ce8efa5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X=trn_array,\n",
    "    y=trn_label,\n",
    "    eval_set=(vld_array, vld_label),\n",
    "    eval_metric=['auc', 'binary_logloss'],\n",
    "    early_stopping_rounds=100,\n",
    "    verbose=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54966753-7e21-4a35-87ea-47424da14a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model_checkpoints/lgbm_discriminator.lgb']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, './model_checkpoints/lgbm_discriminator.lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b98bb6-e608-4e6e-8d6b-82823c9eebf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
