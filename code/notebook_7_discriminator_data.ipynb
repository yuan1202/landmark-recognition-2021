{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0ca8ba-d913-45a6-a1ca-82a6bff8d15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used memory: 2.96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Any\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "\n",
    "import timm\n",
    "\n",
    "import psutil\n",
    "def get_used_memory():\n",
    "    return psutil.Process(os.getpid()).memory_info().vms/1024**3\n",
    "def get_used_memory_txt():\n",
    "    return 'Used memory: {:.2f}'.format(get_used_memory())\n",
    "initial_used_memory=get_used_memory()\n",
    "print(get_used_memory_txt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf327fca-3ad7-438e-be00-fec1045c2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# parameters\n",
    "\n",
    "MODEL_DIR = './model_checkpoints/'\n",
    "DATA_DIR = '../input/'\n",
    "LOG_DIR = './logs/'\n",
    "DEVICE = 'cuda:0'\n",
    "MODEL_NAME = 'rexnet_200'\n",
    "\n",
    "TRAIN_STEP = 0\n",
    "FOLD = 0\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "USE_AMP = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d035292f-b5db-4c8b-9cc2-c9193d1cbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PROTOCOL=4  # there are issues with pickle.HIGHEST_PROTOCOL unsing local recent python versions and then kaggle kernels\n",
    "\n",
    "def read_pickle(filename):\n",
    "    ### LOAD PICKLE\n",
    "    with open(filename, \"rb\") as pfile:\n",
    "        x = pickle.load(pfile)\n",
    "    return x\n",
    "\n",
    "def save_pickle(x, filename=None, makedirs=True):\n",
    "    if makedirs and os.path.dirname(filename)!='': os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'wb') as pfile:\n",
    "        pickle.dump(x, pfile, protocol=PICKLE_PROTOCOL)\n",
    "\n",
    "def to_hex_id(i):\n",
    "    #return i.to_bytes(((i.bit_length() + 7) // 8),\"big\").hex(), \n",
    "    #return hex(i)[2:]\n",
    "    return format(i, '#018x')[2:]\n",
    "\n",
    "def to_int_id(id_):\n",
    "    return int(id_, 16)\n",
    "\n",
    "adversarials_dict=read_pickle(\"../input/adversarials.pkl\")\n",
    "best_friends_dict=read_pickle(\"../input/best_friends.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea4172e-1fd0-481f-9389-731fc15b6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closer_images(id_, d, top_k=None, threshold=None, return_type='hex', include_query_in_result=True):\n",
    "    \n",
    "    if isinstance(id_, str): id_ = to_int_id(id_)\n",
    "    \n",
    "    ids, vals = d[id_]\n",
    "    \n",
    "    if not include_query_in_result:\n",
    "        sel = [x!=id_ for x in ids]\n",
    "        ids = ids[sel]\n",
    "        vals = vals[sel]\n",
    "        \n",
    "    if top_k is not None:\n",
    "        ids = ids[:top_k]\n",
    "        vals = vals[:top_k]\n",
    "    \n",
    "    if threshold is not None:\n",
    "        sel = [x>=threshold for x in vals]\n",
    "        ids = ids[sel]\n",
    "        vals = vals[sel]\n",
    "    \n",
    "    if return_type == 'hex':\n",
    "        ids = [to_hex_id(x) for x in ids]\n",
    "    \n",
    "    return ids, vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f2e933-b7a7-4087-8b92-f2b6e7889e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "\n",
    "# num_imgs = 600_000\n",
    "\n",
    "# list_records = df_train[['id', 'landmark_id']].to_dict('records')\n",
    "# np.random.shuffle(list_records)\n",
    "# list_records_sample = list_records[:num_imgs]\n",
    "# list_ids_train = df_train['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc6f9a8-336c-4113-8ea7-fb90695a6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bf_per_query = 3\n",
    "num_adv_per_query = 4\n",
    "list_id, list_id_crossed = [], []\n",
    "list_same_landmark = []\n",
    "arr_ids = df_train.id.apply(lambda x: to_int_id(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8019668e-ff28-460c-b80d-fcf82372d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1580470/1580470 [02:56<00:00, 8958.92it/s] \n"
     ]
    }
   ],
   "source": [
    "for id_ in tqdm(arr_ids):\n",
    "    \n",
    "    # Best Friends\n",
    "    qt = len(best_friends_dict[id_][1][1:])\n",
    "    if qt > 0:\n",
    "        if qt < num_bf_per_query:\n",
    "            ids_bf = np.random.choice(best_friends_dict[id_][0][1:], qt, p=softmax(best_friends_dict[id_][1][1:]))\n",
    "        else:\n",
    "            ids_bf = np.random.choice(best_friends_dict[id_][0][1:], num_bf_per_query, p=softmax(best_friends_dict[id_][1][1:]))\n",
    "    else:\n",
    "        ids_bf = [] \n",
    "    \n",
    "    # Adversarials\n",
    "    qt = len(adversarials_dict[id_][1][1:])\n",
    "    if qt > 0:\n",
    "        if qt < num_bf_per_query:\n",
    "            ids_adv = np.random.choice(adversarials_dict[id_][0][1:], qt, p=softmax(adversarials_dict[id_][1][1:]))\n",
    "        else:\n",
    "            ids_adv = np.random.choice(adversarials_dict[id_][0][1:], num_bf_per_query, p=softmax(adversarials_dict[id_][1][1:]))\n",
    "    else:\n",
    "        ids_adv = []\n",
    "    \n",
    "    ids_bf = [to_hex_id(x) for x in ids_bf]\n",
    "    ids_adv = [to_hex_id(x) for x in ids_adv]\n",
    "    \n",
    "    list_id.append(np.repeat(id_, len(ids_bf)+len(ids_adv)))\n",
    "    list_id_crossed.append(ids_bf + ids_adv)\n",
    "    list_same_landmark.extend([1 for _ in range(len(ids_bf))] + [0 for _ in range(len(ids_adv))])\n",
    "    \n",
    "df_vector_discriminator = pd.DataFrame({\n",
    "    'img_id' : np.concatenate(list_id),\n",
    "    'img_id_crossed' : np.concatenate(list_id_crossed),\n",
    "    'target' : list_same_landmark\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a701d9c-ab10-4353-81d8-4d3be6e8451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_discriminator['img_id'] = df_vector_discriminator['img_id'].apply(lambda x: to_hex_id(x))\n",
    "imgid2lmid = df_train.to_dict('records')\n",
    "imgid2lmid = {d['id']: d['landmark_id'] for d in imgid2lmid}\n",
    "df_vector_discriminator['landmark_id'] = df_vector_discriminator['img_id'].apply(lambda x: imgid2lmid[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f135a55-626b-417b-ae18-1e674ffad76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmid2class = {id_: i for i, id_ in enumerate(sorted(df_vector_discriminator['landmark_id'].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b0d51e0e-5169-4fdf-a8a1-46bd420c726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_discriminator['landmark_class'] = df_vector_discriminator['landmark_id'].apply(lambda x: lmid2class[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3677c6d-9179-43da-8b5f-a887a14b52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db350a69-3693-4ade-8230-927a05ed42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_discriminator['fold'] = -1\n",
    "\n",
    "for i, (_, vld_idx) in enumerate(skf.split(df_vector_discriminator.index, df_vector_discriminator['landmark_class'])):\n",
    "    df_vector_discriminator['fold'].iloc[vld_idx] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3f1287d1-d5e9-4fec-bbbf-7e3121f07f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector_discriminator.to_csv('../input/train_adversarials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "740e3882-1045-477f-a99a-5971f1568e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_id_crossed</th>\n",
       "      <th>target</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>landmark_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>af82f37db037efd0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>183180bf74cd6933</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>878fb29295c7ae0e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>b12506b7608ab2e4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>f62cdcd356702122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354300</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>5ba296fb81175d30</td>\n",
       "      <td>1</td>\n",
       "      <td>203092</td>\n",
       "      <td>81312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354301</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>9401fad4c497e1f9</td>\n",
       "      <td>1</td>\n",
       "      <td>203092</td>\n",
       "      <td>81312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354302</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>5a7934544b8cea76</td>\n",
       "      <td>0</td>\n",
       "      <td>203092</td>\n",
       "      <td>81312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354303</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>275839a063cb77b7</td>\n",
       "      <td>0</td>\n",
       "      <td>203092</td>\n",
       "      <td>81312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9354304</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>0f32dea69232ffed</td>\n",
       "      <td>0</td>\n",
       "      <td>203092</td>\n",
       "      <td>81312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9354305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   img_id    img_id_crossed  target  landmark_id  \\\n",
       "0        17660ef415d37059  af82f37db037efd0       1            1   \n",
       "1        17660ef415d37059  183180bf74cd6933       1            1   \n",
       "2        17660ef415d37059  878fb29295c7ae0e       1            1   \n",
       "3        17660ef415d37059  b12506b7608ab2e4       0            1   \n",
       "4        17660ef415d37059  f62cdcd356702122       0            1   \n",
       "...                   ...               ...     ...          ...   \n",
       "9354300  d9e338c530dca106  5ba296fb81175d30       1       203092   \n",
       "9354301  d9e338c530dca106  9401fad4c497e1f9       1       203092   \n",
       "9354302  d9e338c530dca106  5a7934544b8cea76       0       203092   \n",
       "9354303  d9e338c530dca106  275839a063cb77b7       0       203092   \n",
       "9354304  d9e338c530dca106  0f32dea69232ffed       0       203092   \n",
       "\n",
       "         landmark_class  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "9354300           81312  \n",
       "9354301           81312  \n",
       "9354302           81312  \n",
       "9354303           81312  \n",
       "9354304           81312  \n",
       "\n",
       "[9354305 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vector_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3884a3f1-63a6-49ff-a534-a899b9c9262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('../input/model_v0.6_landmark_embeddings_f16.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9be90ec1-2ac0-4073-b56d-5d40c6c400e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17660ef415d37059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92b6290d571448f6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cd41bf948edc0340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fb09f1e98c6d2f70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25c9dfc7ea69838d</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580465</th>\n",
       "      <td>72c3b1c367e3d559</td>\n",
       "      <td>203092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580466</th>\n",
       "      <td>7a6a2d9ea92684a6</td>\n",
       "      <td>203092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580467</th>\n",
       "      <td>9401fad4c497e1f9</td>\n",
       "      <td>203092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580468</th>\n",
       "      <td>aacc960c9a228b5f</td>\n",
       "      <td>203092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580469</th>\n",
       "      <td>d9e338c530dca106</td>\n",
       "      <td>203092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1580470 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  landmark_id\n",
       "0        17660ef415d37059            1\n",
       "1        92b6290d571448f6            1\n",
       "2        cd41bf948edc0340            1\n",
       "3        fb09f1e98c6d2f70            1\n",
       "4        25c9dfc7ea69838d            7\n",
       "...                   ...          ...\n",
       "1580465  72c3b1c367e3d559       203092\n",
       "1580466  7a6a2d9ea92684a6       203092\n",
       "1580467  9401fad4c497e1f9       203092\n",
       "1580468  aacc960c9a228b5f       203092\n",
       "1580469  d9e338c530dca106       203092\n",
       "\n",
       "[1580470 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2b36d666-c37b-42e9-8ec3-c0e8464399bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1580470, 512)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "051f0590-c103-47d3-b6ce-3bcca35ffc3f",
   "metadata": {},
   "source": [
    "# Create a dict to associate all imgs to corresponding landmark\n",
    "dict_landmarks, dict_img_to_landmark = {}, {}\n",
    "\n",
    "for record in tqdm(list_records):\n",
    "    \n",
    "    img_id, landmark = record['id'], record['landmark_id']\n",
    "    \n",
    "    if landmark not in dict_landmarks:\n",
    "        dict_landmarks[landmark] = [img_id]\n",
    "    else:\n",
    "        dict_landmarks[landmark].append(img_id)\n",
    "        \n",
    "    dict_img_to_landmark[img_id] = landmark\n",
    "\n",
    "# Decide which imgs to cross\n",
    "list_crossed, list_landmark_crossed = [], []\n",
    "\n",
    "image_indices = np.arange(len(df_train))\n",
    "\n",
    "for record in tqdm(list_records_sample, position=0):\n",
    "    \n",
    "    img_id, landmark = record['id'], record['landmark_id']\n",
    "    \n",
    "    # Same landmark\n",
    "    if np.random.random() >= 0.5:\n",
    "        same_image = True\n",
    "        while same_image:\n",
    "            img_id_crossed = np.random.choice(dict_landmarks[landmark])\n",
    "            landmark_crossed = landmark\n",
    "            if img_id_crossed != img_id or len(dict_landmarks[landmark])==1:\n",
    "                same_image = False         \n",
    "    \n",
    "    # Other one\n",
    "    else:\n",
    "        same_landmark = True\n",
    "        while same_landmark:\n",
    "            img_id_crossed = df_train['id'].iloc[np.random.choice(image_indices)]\n",
    "            landmark_crossed = dict_img_to_landmark[img_id_crossed]\n",
    "            if landmark_crossed != landmark:\n",
    "                same_landmark = False   \n",
    "    \n",
    "    list_crossed.append(img_id_crossed)\n",
    "    list_landmark_crossed.append(landmark_crossed)\n",
    "\n",
    "    \n",
    "df_vector_discriminator = pd.DataFrame({\n",
    "    'img_id' : [x['id'] for x in list_records_sample],\n",
    "    'landmark_id' : [x['landmark_id'] for x in list_records_sample],\n",
    "    'img_id_crossed' : list_crossed,\n",
    "    'landmark_id_crossed' : list_landmark_crossed\n",
    "})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5a983b4-a3aa-4b37-bbfa-89cd528be6e5",
   "metadata": {},
   "source": [
    "df_vector_discriminator['target'] = df_vector_discriminator.apply(lambda x : 1 if x['landmark_id']==x['landmark_id_crossed'] else 0 ,axis=1)\n",
    "print(df_vector_discriminator['target'].value_counts())\n",
    "\n",
    "df_vector_discriminator['same_image'] = df_vector_discriminator.apply(lambda x : 1 if x['img_id']==x['img_id_crossed'] else 0 ,axis=1)\n",
    "print(df_vector_discriminator['same_image'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f5c6827-0502-4229-87db-22ca6c2fbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_module(nn.Module):\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "def gem(x, p=3, eps=1e-6):\n",
    "    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n",
    "        super(GeM,self).__init__()\n",
    "        if p_trainable:\n",
    "            self.p = Parameter(torch.ones(1)*p)\n",
    "        else:\n",
    "            self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return gem(x, p=self.p, eps=self.eps)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n",
    "\n",
    "class Landmark_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.backbone = timm.create_model('rexnet_100', pretrained=True)\n",
    "        self.backbone = timm.create_model('res2net50_14w_8s', pretrained=True)\n",
    "        self.global_pool = GeM()\n",
    "        self.neck = nn.Sequential(\n",
    "            nn.Linear(self.backbone.num_features, 512, bias=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            Swish_module()\n",
    "        )\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.head = nn.Sequential(nn.Linear(512*3, 1, bias=True))\n",
    "        \n",
    "    def forward(self, x0, x1):\n",
    "        embd0 = self.neck(self.global_pool(self.backbone(x0))[:, :, 0, 0])\n",
    "        embd1 = self.neck(self.global_pool(self.backbone(x1))[:, :, 0, 0])\n",
    "        embd2 = (embd1 - embd0).abs()\n",
    "        embd = torch.cat([embd0, embd1, embd2], dim=1)\n",
    "        return self.head(embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9ad8d02-79f5-4ebc-b121-c3e9370a19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Landmark_Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8cb7183-8b4a-43c4-b411-e1f4e370e8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2629],\n",
       "        [-0.8639],\n",
       "        [-0.5148],\n",
       "        [-0.4444],\n",
       "        [-0.9016],\n",
       "        [-0.4894],\n",
       "        [-0.0449],\n",
       "        [-0.4814]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(torch.randn(8, 3, 512, 512), torch.randn(8, 3, 512, 512))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
