{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0ca8ba-d913-45a6-a1ca-82a6bff8d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import albumentations\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR, ReduceLROnPlateau\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cccb00-d75d-4a09-a995-6dade3afb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = torch.load('./model_checkpoints/rexnet_200_fold0_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe77829c-4778-42db-81f0-6d662a37c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_only_weight = {k[7:] if k.startswith('module.') else k: v for k, v in load['model_state_dict'].items() if 'metric_classify' not in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45228e65-8547-4fe4-9353-35e5df320a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RexNet20_Landmark(out_dim=81313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908ace6b-bf48-4daa-86ce-d529682eddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['metric_classify.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_only_weight, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6971c0d0-a951-48ad-a447-b960866f8aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.7172e-01,  8.2092e-01,  7.9170e-01],\n",
       "          [ 1.4248e-01,  5.1747e-01,  9.5074e-01],\n",
       "          [-1.3655e-01,  3.9823e-02,  4.8910e-01]],\n",
       "\n",
       "         [[-5.8814e-02, -7.2180e-02, -8.2899e-02],\n",
       "          [-6.8625e-02, -2.4449e-01, -8.8749e-02],\n",
       "          [-1.5222e-01, -1.1218e-01, -1.6798e-01]],\n",
       "\n",
       "         [[ 5.2349e-04, -6.9481e-01, -6.2166e-01],\n",
       "          [-2.6621e-02, -1.6972e-01, -8.4368e-01],\n",
       "          [ 1.1064e-01,  9.8290e-02, -4.2522e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.9963e-02,  1.3153e-01,  3.4543e-02],\n",
       "          [ 7.0920e-02,  2.9942e-01,  2.3516e-01],\n",
       "          [-2.1382e-02,  2.5734e-01,  1.2570e-01]],\n",
       "\n",
       "         [[-4.6481e-02, -2.0397e-01, -3.0559e-01],\n",
       "          [-3.4090e-01, -3.7177e-01, -4.9805e-01],\n",
       "          [-2.9186e-01, -2.1923e-01, -2.0162e-01]],\n",
       "\n",
       "         [[-2.0391e-01, -4.8950e-01, -4.8962e-01],\n",
       "          [-6.3668e-01, -8.8429e-01, -8.0734e-01],\n",
       "          [-4.6318e-01, -5.7828e-01, -5.3034e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.8993e-02, -6.4054e-02, -9.8497e-02],\n",
       "          [ 1.9389e-02, -8.4509e-02,  7.6068e-01],\n",
       "          [-8.4697e-02,  2.8049e-01,  2.0492e+00]],\n",
       "\n",
       "         [[ 8.2067e-02,  9.2723e-02,  6.1357e-02],\n",
       "          [ 8.8145e-02, -3.2768e-01,  2.0506e-01],\n",
       "          [ 8.5463e-02, -2.8041e-01,  3.2872e-01]],\n",
       "\n",
       "         [[ 7.6107e-02,  1.4707e-01,  1.1426e-01],\n",
       "          [ 3.3641e-02, -2.8195e-01, -3.8469e-02],\n",
       "          [-7.5433e-02, -3.9740e-01, -3.1966e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.8509e-01, -1.7497e-01, -2.0292e-01],\n",
       "          [-2.7631e-01, -3.5387e-01, -2.9826e-01],\n",
       "          [-3.6285e-01, -5.2090e-01, -3.4354e-01]],\n",
       "\n",
       "         [[ 1.3440e-01,  1.2775e-01,  3.9416e-02],\n",
       "          [ 1.6822e-01,  4.4055e-02,  8.4518e-02],\n",
       "          [ 1.9053e-01,  1.9184e-02,  1.0318e-01]],\n",
       "\n",
       "         [[ 2.0064e-01,  2.3904e-01,  6.3774e-02],\n",
       "          [ 3.8402e-01,  1.9872e-01,  2.7769e-01],\n",
       "          [ 5.0167e-01,  2.7331e-01,  3.1922e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.3920e-02,  9.5578e-01, -8.7570e-02],\n",
       "          [-5.7485e-02, -7.8547e-01, -1.2231e-01],\n",
       "          [ 5.8968e-02, -1.0347e-01,  4.4727e-02]],\n",
       "\n",
       "         [[-1.6432e-01,  1.4490e+00, -8.0902e-02],\n",
       "          [ 3.9498e-03, -1.0504e+00, -6.8272e-02],\n",
       "          [ 5.9495e-02, -2.2955e-02,  1.7646e-01]],\n",
       "\n",
       "         [[-2.4400e-01,  6.8130e-01, -6.3252e-02],\n",
       "          [-5.1348e-03, -5.5771e-01, -7.0137e-02],\n",
       "          [-4.5085e-03, -1.5457e-01,  1.4052e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6420e-01, -1.2883e-01, -1.6841e-01],\n",
       "          [-1.5357e-01,  8.4716e-03,  1.7020e-01],\n",
       "          [-7.4009e-02,  1.2729e-01,  3.8792e-01]],\n",
       "\n",
       "         [[ 9.1484e-03,  3.9038e-02, -9.0519e-02],\n",
       "          [ 1.2136e-02,  3.1013e-01,  2.2672e-01],\n",
       "          [ 4.5558e-02,  3.1846e-01,  4.9372e-01]],\n",
       "\n",
       "         [[ 1.6619e-02, -4.1523e-03,  1.7261e-02],\n",
       "          [-5.6904e-02, -2.6997e-01, -8.7379e-01],\n",
       "          [ 7.0510e-02, -6.0487e-01, -2.2378e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_only_weight['net.stem.conv.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5e8217a-2881-460c-8b01-2df4f9e3f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 2.2430e-01,  6.9903e-01,  5.6202e-01],\n",
       "          [ 1.1903e-01,  3.8059e-01,  7.5248e-01],\n",
       "          [-8.1981e-02, -4.4104e-02,  3.5829e-01]],\n",
       "\n",
       "         [[ 1.3307e-03,  2.7781e-02, -2.5923e-02],\n",
       "          [-7.9979e-03, -1.6903e-01,  7.9982e-03],\n",
       "          [-6.0836e-02, -2.0887e-02, -4.6925e-02]],\n",
       "\n",
       "         [[-8.6158e-02, -6.4904e-01, -5.4179e-01],\n",
       "          [-1.1733e-01, -1.4502e-01, -7.0485e-01],\n",
       "          [ 4.6100e-02,  9.1906e-02, -2.8695e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4574e-03,  6.9474e-03, -6.7421e-02],\n",
       "          [ 6.1109e-02,  2.0079e-01,  1.3821e-01],\n",
       "          [-1.1119e-01,  9.4573e-02, -2.4211e-02]],\n",
       "\n",
       "         [[ 6.2152e-02, -8.4461e-02, -1.4320e-01],\n",
       "          [-4.8951e-02, -1.4872e-01, -2.7735e-01],\n",
       "          [-1.6497e-01, -1.4559e-01, -1.0806e-01]],\n",
       "\n",
       "         [[-9.9388e-02, -2.5173e-01, -2.0862e-01],\n",
       "          [-1.3840e-01, -3.3261e-01, -3.4793e-01],\n",
       "          [-2.2924e-01, -3.6122e-01, -3.0744e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.4114e-02, -1.3582e-01, -2.8251e-01],\n",
       "          [-3.7102e-02, -9.3506e-02,  2.7990e-01],\n",
       "          [-8.5517e-02,  2.6132e-01,  1.3579e+00]],\n",
       "\n",
       "         [[-4.9747e-03,  6.7565e-02, -6.9533e-02],\n",
       "          [ 3.7937e-02, -2.0367e-01,  1.9743e-02],\n",
       "          [ 1.0158e-01, -1.2652e-01,  1.7104e-01]],\n",
       "\n",
       "         [[-3.0833e-02,  1.7066e-01,  1.7563e-03],\n",
       "          [ 4.3378e-03, -3.1341e-02, -4.2523e-02],\n",
       "          [-3.0699e-02, -1.0059e-01, -2.3387e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 3.9878e-02, -7.7473e-02, -2.2213e-02],\n",
       "          [-8.2864e-02, -2.2637e-01, -6.3943e-02],\n",
       "          [-1.4801e-01, -3.4522e-01, -1.1531e-01]],\n",
       "\n",
       "         [[ 8.5496e-02, -1.5083e-03,  2.0707e-02],\n",
       "          [-2.8780e-03, -1.1754e-01,  2.7333e-02],\n",
       "          [-4.3049e-02, -1.7558e-01,  1.0641e-03]],\n",
       "\n",
       "         [[ 1.1461e-01,  6.0525e-02,  2.4147e-02],\n",
       "          [ 5.4505e-02, -5.6702e-02,  9.7386e-02],\n",
       "          [ 8.7317e-03, -1.0979e-01,  4.6822e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.3345e-01,  7.8347e-01, -8.0291e-02],\n",
       "          [-2.2011e-02, -6.4707e-01, -1.8000e-02],\n",
       "          [ 9.5568e-02, -3.1064e-02,  5.5265e-02]],\n",
       "\n",
       "         [[-1.9625e-01,  1.2049e+00, -1.4177e-01],\n",
       "          [ 2.1113e-02, -9.6466e-01, -3.6100e-02],\n",
       "          [ 8.7857e-02, -1.0589e-02,  8.8970e-02]],\n",
       "\n",
       "         [[-1.8348e-01,  5.3205e-01, -5.9067e-02],\n",
       "          [ 8.0457e-02, -4.2214e-01,  5.6336e-03],\n",
       "          [ 1.0531e-01, -9.9673e-02,  4.0684e-02]]],\n",
       "\n",
       "\n",
       "        [[[-5.3098e-03, -8.3169e-03, -1.0512e-02],\n",
       "          [-1.3162e-01, -6.3494e-02,  1.7368e-01],\n",
       "          [-2.0350e-02, -3.8241e-02,  1.7005e-01]],\n",
       "\n",
       "         [[ 1.4857e-02, -9.2072e-03, -1.2368e-01],\n",
       "          [-5.6445e-02,  1.5078e-01,  1.3688e-01],\n",
       "          [-8.1893e-02, -2.2324e-02,  5.2985e-02]],\n",
       "\n",
       "         [[ 2.2781e-02,  4.2928e-04,  7.8703e-02],\n",
       "          [ 1.5938e-01,  3.7165e-02, -3.2458e-01],\n",
       "          [ 3.4811e-01, -2.5457e-01, -1.6873e+00]]]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.stem.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f95e0e2-7e11-4c9c-b011-a97c07932e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 2.7172e-01,  8.2092e-01,  7.9170e-01],\n",
       "          [ 1.4248e-01,  5.1747e-01,  9.5074e-01],\n",
       "          [-1.3655e-01,  3.9823e-02,  4.8910e-01]],\n",
       "\n",
       "         [[-5.8814e-02, -7.2180e-02, -8.2899e-02],\n",
       "          [-6.8625e-02, -2.4449e-01, -8.8749e-02],\n",
       "          [-1.5222e-01, -1.1218e-01, -1.6798e-01]],\n",
       "\n",
       "         [[ 5.2349e-04, -6.9481e-01, -6.2166e-01],\n",
       "          [-2.6621e-02, -1.6972e-01, -8.4368e-01],\n",
       "          [ 1.1064e-01,  9.8290e-02, -4.2522e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 7.9963e-02,  1.3153e-01,  3.4543e-02],\n",
       "          [ 7.0920e-02,  2.9942e-01,  2.3516e-01],\n",
       "          [-2.1382e-02,  2.5734e-01,  1.2570e-01]],\n",
       "\n",
       "         [[-4.6481e-02, -2.0397e-01, -3.0559e-01],\n",
       "          [-3.4090e-01, -3.7177e-01, -4.9805e-01],\n",
       "          [-2.9186e-01, -2.1923e-01, -2.0162e-01]],\n",
       "\n",
       "         [[-2.0391e-01, -4.8950e-01, -4.8962e-01],\n",
       "          [-6.3668e-01, -8.8429e-01, -8.0734e-01],\n",
       "          [-4.6318e-01, -5.7828e-01, -5.3034e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 9.8993e-02, -6.4054e-02, -9.8497e-02],\n",
       "          [ 1.9389e-02, -8.4509e-02,  7.6068e-01],\n",
       "          [-8.4697e-02,  2.8049e-01,  2.0492e+00]],\n",
       "\n",
       "         [[ 8.2067e-02,  9.2723e-02,  6.1357e-02],\n",
       "          [ 8.8145e-02, -3.2768e-01,  2.0506e-01],\n",
       "          [ 8.5463e-02, -2.8041e-01,  3.2872e-01]],\n",
       "\n",
       "         [[ 7.6107e-02,  1.4707e-01,  1.1426e-01],\n",
       "          [ 3.3641e-02, -2.8195e-01, -3.8469e-02],\n",
       "          [-7.5433e-02, -3.9740e-01, -3.1966e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.8509e-01, -1.7497e-01, -2.0292e-01],\n",
       "          [-2.7631e-01, -3.5387e-01, -2.9826e-01],\n",
       "          [-3.6285e-01, -5.2090e-01, -3.4354e-01]],\n",
       "\n",
       "         [[ 1.3440e-01,  1.2775e-01,  3.9416e-02],\n",
       "          [ 1.6822e-01,  4.4055e-02,  8.4518e-02],\n",
       "          [ 1.9053e-01,  1.9184e-02,  1.0318e-01]],\n",
       "\n",
       "         [[ 2.0064e-01,  2.3904e-01,  6.3774e-02],\n",
       "          [ 3.8402e-01,  1.9872e-01,  2.7769e-01],\n",
       "          [ 5.0167e-01,  2.7331e-01,  3.1922e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.3920e-02,  9.5578e-01, -8.7570e-02],\n",
       "          [-5.7485e-02, -7.8547e-01, -1.2231e-01],\n",
       "          [ 5.8968e-02, -1.0347e-01,  4.4727e-02]],\n",
       "\n",
       "         [[-1.6432e-01,  1.4490e+00, -8.0902e-02],\n",
       "          [ 3.9498e-03, -1.0504e+00, -6.8272e-02],\n",
       "          [ 5.9495e-02, -2.2955e-02,  1.7646e-01]],\n",
       "\n",
       "         [[-2.4400e-01,  6.8130e-01, -6.3252e-02],\n",
       "          [-5.1348e-03, -5.5771e-01, -7.0137e-02],\n",
       "          [-4.5085e-03, -1.5457e-01,  1.4052e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.6420e-01, -1.2883e-01, -1.6841e-01],\n",
       "          [-1.5357e-01,  8.4716e-03,  1.7020e-01],\n",
       "          [-7.4009e-02,  1.2729e-01,  3.8792e-01]],\n",
       "\n",
       "         [[ 9.1484e-03,  3.9038e-02, -9.0519e-02],\n",
       "          [ 1.2136e-02,  3.1013e-01,  2.2672e-01],\n",
       "          [ 4.5558e-02,  3.1846e-01,  4.9372e-01]],\n",
       "\n",
       "         [[ 1.6619e-02, -4.1523e-03,  1.7261e-02],\n",
       "          [-5.6904e-02, -2.6997e-01, -8.7379e-01],\n",
       "          [ 7.0510e-02, -6.0487e-01, -2.2378e+00]]]], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.stem.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c3775b0-4b6a-47c7-a683-ce92d224cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(RexNet20_Landmark(out_dim=81313)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe4af2f-f7e8-4089-ae3b-0e274a1371e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['module.metric_classify.weight'], unexpected_keys=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_only_weight, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba8841-3792-4995-b2d8-fba3cebe39c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf69705b-c586-4808-a152-f94863ca5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# parameters\n",
    "\n",
    "MODEL_DIR = './model_checkpoints/'\n",
    "DATA_DIR = '../input/'\n",
    "LOG_DIR = './logs/'\n",
    "DEVICE = 'cuda:0'\n",
    "MODEL_NAME = 'rexnet_200'\n",
    "\n",
    "TRAIN_STEP = 0\n",
    "FOLD = 0\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-4\n",
    "USE_AMP = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30490979-648e-4768-b6bf-76784472ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# utils\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d592ec-3a42-49c0-acd4-7b0801807aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# data pipeline definitions\n",
    "\n",
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, csv, mode, transform=None):\n",
    "\n",
    "        self.csv = csv.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.csv.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.csv.iloc[index]\n",
    "\n",
    "        image = cv2.imread(row.filepath)[:,:,::-1]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            res = self.transform(image=image)\n",
    "            image = res['image'].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "\n",
    "        image = image.transpose(2, 0, 1)\n",
    "        if self.mode == 'test':\n",
    "            return torch.tensor(image)\n",
    "        else:\n",
    "            return torch.tensor(image), torch.tensor(row.landmark_id)\n",
    "\n",
    "\n",
    "def get_transforms():\n",
    "\n",
    "    transforms_train = albumentations.Compose([\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.ImageCompression(quality_lower=99, quality_upper=100),\n",
    "        albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=10, border_mode=0, p=0.7),\n",
    "        albumentations.Cutout(max_h_size=int(IMAGE_SIZE * 0.4), max_w_size=int(IMAGE_SIZE * 0.4), num_holes=1, p=0.5),\n",
    "        albumentations.Normalize()\n",
    "    ])\n",
    "\n",
    "    transforms_val = albumentations.Compose([\n",
    "        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        albumentations.Normalize()\n",
    "    ])\n",
    "\n",
    "    return transforms_train, transforms_val\n",
    "\n",
    "\n",
    "def get_df():\n",
    "\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, 'train_0.csv'))\n",
    "\n",
    "    if TRAIN_STEP == 0:\n",
    "        # df_train = pd.read_csv(os.path.join(DATA_DIR, 'train_url.csv')).drop(columns=['url'])\n",
    "        df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "    else:\n",
    "        cls_81313 = df.landmark_id.unique()\n",
    "        # df_train = pd.read_csv(os.path.join(DATA_DIR, 'train_url.csv')).drop(columns=['url']).set_index('landmark_id').loc[cls_81313].reset_index()\n",
    "        df_train = pd.read_csv(os.path.join(DATA_DIR, 'train.csv')).set_index('landmark_id').loc[cls_81313].reset_index()\n",
    "        \n",
    "    df_train['filepath'] = df_train['id'].apply(lambda x: os.path.join(DATA_DIR, 'train', x[0], x[1], x[2], f'{x}.jpg'))\n",
    "    df = df_train.merge(df, on=['id','landmark_id'], how='left')\n",
    "\n",
    "    landmark_id2idx = {landmark_id: idx for idx, landmark_id in enumerate(sorted(df['landmark_id'].unique()))}\n",
    "    idx2landmark_id = {idx: landmark_id for idx, landmark_id in enumerate(sorted(df['landmark_id'].unique()))}\n",
    "    df['landmark_id'] = df['landmark_id'].map(landmark_id2idx)\n",
    "\n",
    "    out_dim = df.landmark_id.nunique()\n",
    "\n",
    "    return df, out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b38e724-5c19-45c8-ae5a-65875a9bf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# model definitions\n",
    "\n",
    "class Swish(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.sigmoid(i)\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "        sigmoid_i = torch.sigmoid(i)\n",
    "        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n",
    "\n",
    "\n",
    "class Swish_module(nn.Module):\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        return Swish.apply(x)\n",
    "\n",
    "\n",
    "class DenseCrossEntropy(nn.Module):\n",
    "    @autocast()\n",
    "    def forward(self, x, target):\n",
    "        x = x.float()\n",
    "        target = target.float()\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "\n",
    "        loss = -logprobs * target\n",
    "        loss = loss.sum(-1)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "class ArcMarginProduct_subcenter(nn.Module):\n",
    "    def __init__(self, in_features, out_features, k=3):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features*k, in_features))\n",
    "        self.reset_parameters()\n",
    "        self.k = k\n",
    "        self.out_features = out_features\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "    \n",
    "    @autocast()\n",
    "    def forward(self, features):\n",
    "        cosine_all = F.linear(F.normalize(features), F.normalize(self.weight))\n",
    "        cosine_all = cosine_all.view(-1, self.out_features, self.k)\n",
    "        cosine, _ = torch.max(cosine_all, dim=2)\n",
    "        return cosine   \n",
    "\n",
    "\n",
    "class ArcFaceLossAdaptiveMargin(nn.modules.Module):\n",
    "    def __init__(self, margins, s=30.0):\n",
    "        super().__init__()\n",
    "        self.crit = DenseCrossEntropy()\n",
    "        self.s = s\n",
    "        self.margins = margins\n",
    "            \n",
    "    @autocast()\n",
    "    def forward(self, logits, labels, out_dim):\n",
    "        ms = []\n",
    "        ms = self.margins[labels.cpu().numpy()]\n",
    "        cos_m = torch.from_numpy(np.cos(ms)).float().cuda()\n",
    "        sin_m = torch.from_numpy(np.sin(ms)).float().cuda()\n",
    "        th = torch.from_numpy(np.cos(math.pi - ms)).float().cuda()\n",
    "        mm = torch.from_numpy(np.sin(math.pi - ms) * ms).float().cuda()\n",
    "        labels = F.one_hot(labels, out_dim).float()\n",
    "        logits = logits.float()\n",
    "        cosine = logits\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * cos_m.view(-1, 1) - sine * sin_m.view(-1, 1)\n",
    "        phi = torch.where(cosine > th.view(-1, 1), phi, cosine - mm.view(-1, 1))\n",
    "        output = (labels * phi) + ((1.0 - labels) * cosine)\n",
    "        output *= self.s\n",
    "        loss = self.crit(output, labels)\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.p=p\n",
    "        self.eps=eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return F.avg_pool2d(x.clamp(min=self.eps).pow(self.p), (x.size(-2), x.size(-1))).pow(1./self.p)\n",
    "\n",
    "\n",
    "class RexNet20_Landmark(nn.Module):\n",
    "\n",
    "    def __init__(self, out_dim, load_pretrained=True):\n",
    "        super(RexNet20_Landmark, self).__init__()\n",
    "\n",
    "        self.net = timm.create_model('rexnet_200', pretrained=load_pretrained)\n",
    "        self.feat = nn.Linear(self.net.features[-1].out_channels, 512)\n",
    "        self.swish = Swish_module()\n",
    "        self.metric_classify = ArcMarginProduct_subcenter(512, out_dim)\n",
    "        self.net.head.global_pool = GeM()\n",
    "        self.net.head.fc = nn.Identity()\n",
    "\n",
    "    def extract(self, x):\n",
    "        return self.net(x).squeeze()\n",
    "\n",
    "    @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.extract(x)\n",
    "        logits_m = self.metric_classify(self.swish(self.feat(x)))\n",
    "        return logits_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39590533-1117-48d0-a5ed-a1b7437c33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# training utils\n",
    "\n",
    "def global_average_precision_score(\n",
    "        y_true: Dict[Any, Any],\n",
    "        y_pred: Dict[Any, Tuple[Any, float]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute Global Average Precision score (GAP)\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : Dict[Any, Any]\n",
    "        Dictionary with query ids and true ids for query samples\n",
    "    y_pred : Dict[Any, Tuple[Any, float]]\n",
    "        Dictionary with query ids and predictions (predicted id, confidence\n",
    "        level)\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        GAP score\n",
    "    \"\"\"\n",
    "    indexes = list(y_pred.keys())\n",
    "    indexes.sort(\n",
    "        key=lambda x: -y_pred[x][1],\n",
    "    )\n",
    "    queries_with_target = len([i for i in y_true.values() if i is not None])\n",
    "    correct_predictions = 0\n",
    "    total_score = 0.\n",
    "    for i, k in enumerate(indexes, 1):\n",
    "        relevance_of_prediction_i = 0\n",
    "        if y_true[k] == y_pred[k][0]:\n",
    "            correct_predictions += 1\n",
    "            relevance_of_prediction_i = 1\n",
    "        precision_at_rank_i = correct_predictions / i\n",
    "        total_score += precision_at_rank_i * relevance_of_prediction_i\n",
    "\n",
    "    return 1 / queries_with_target * total_score\n",
    "    \n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, scaler):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if not USE_AMP:\n",
    "            logits_m = model(data)\n",
    "            loss = criterion(logits_m, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            with autocast():\n",
    "                logits_m = model(data)\n",
    "                loss = criterion(logits_m, target)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "            \n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(model, valid_loader, criterion, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    PRODS_M = []\n",
    "    PREDS_M = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(valid_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            logits_m = model(data)\n",
    "\n",
    "            lmax_m = logits_m.max(1)\n",
    "            probs_m = lmax_m.values\n",
    "            preds_m = lmax_m.indices\n",
    "\n",
    "            PRODS_M.append(probs_m.detach().cpu())\n",
    "            PREDS_M.append(preds_m.detach().cpu())\n",
    "            TARGETS.append(target.detach().cpu())\n",
    "\n",
    "            loss = criterion(logits_m, target)\n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        val_loss = np.mean(val_loss)\n",
    "        PRODS_M = torch.cat(PRODS_M).numpy()\n",
    "        PREDS_M = torch.cat(PREDS_M).numpy()\n",
    "        TARGETS = torch.cat(TARGETS)\n",
    "\n",
    "    if get_output:\n",
    "        return LOGITS_M\n",
    "    else:\n",
    "        acc_m = (PREDS_M == TARGETS.numpy()).mean() * 100.\n",
    "        y_true = {idx: target if target >=0 else None for idx, target in enumerate(TARGETS)}\n",
    "        y_pred_m = {idx: (pred_cls, conf) for idx, (pred_cls, conf) in enumerate(zip(PREDS_M, PRODS_M))}\n",
    "        gap_m = global_average_precision_score(y_true, y_pred_m)\n",
    "        return val_loss, acc_m, gap_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ec31cd-5bf6-488d-ac8e-007eb08f5694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_dim = 81313\n"
     ]
    }
   ],
   "source": [
    "# get dataframe\n",
    "df, out_dim = get_df()\n",
    "print(f\"out_dim = {out_dim}\")\n",
    "\n",
    "# get adaptive margin\n",
    "tmp = np.sqrt(1 / np.sqrt(df['landmark_id'].value_counts().sort_index().values))\n",
    "margins = (tmp - tmp.min()) / (tmp.max() - tmp.min()) * 0.45 + 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b40235b-0dac-4ad5-9d62-6676aa691c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuan/miniconda3/envs/FULL_ML/lib/python3.8/site-packages/albumentations/augmentations/transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get augmentations\n",
    "transforms_train, transforms_val = get_transforms()\n",
    "\n",
    "# get train and valid dataset\n",
    "df_train = df[df['fold'] != FOLD]\n",
    "df_valid = df[df['fold'] == FOLD].reset_index(drop=True).query(\"index % 15==0\")\n",
    "\n",
    "dataset_train = LandmarkDataset(df_train, 'train', transform=transforms_train)\n",
    "dataset_valid = LandmarkDataset(df_valid, 'val', transform=transforms_val)\n",
    "train_loader = DataLoader(\n",
    "    dataset_train, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42939722-e88c-439c-a9d9-6efc8bdcce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = nn.DataParallel(RexNet20_Landmark(out_dim=out_dim)).to(DEVICE)\n",
    "\n",
    "# loss func\n",
    "def criterion(logits_m, target):\n",
    "    arc = ArcFaceLossAdaptiveMargin(margins=margins, s=80)\n",
    "    loss_m = arc(logits_m, target, out_dim)\n",
    "    return loss_m\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scaler = GradScaler(enabled=True)\n",
    "\n",
    "# scheduler\n",
    "scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(train_loader), pct_start=.05, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "868a11b9-9a63-49f0-9d0f-b26bfb3a351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021Aug21_22H43M16S Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19756 [00:00<?, ?it/s]<ipython-input-5-b77f6e5d16d6>:14: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n",
      "  i = ctx.saved_variables[0]\n",
      "loss: 30.36711, smth: 33.90587:   1%|▏         | 288/19756 [01:47<2:01:34,  2.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-681bf4ee2241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-9e98c14bec33>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion, scaler)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mlogits_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dc9cfe87846a>\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(logits_m, target)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0marc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArcFaceLossAdaptiveMargin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FULL_ML/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/FULL_ML/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-b77f6e5d16d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, logits, labels, out_dim)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mcos_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0msin_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train & valid loop\n",
    "gap_m_max = 0.\n",
    "model_file = os.path.join(MODEL_DIR, f'{MODEL_NAME}_fold{FOLD}.pth')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    curr_time = datetime.strftime(datetime.now(), '%Y%b%d_%HH%MM%SS')\n",
    "    print(curr_time, 'Epoch:', epoch)\n",
    "    \n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, scaler)\n",
    "    val_loss, acc_m, gap_m = val_epoch(model, valid_loader, criterion)\n",
    "\n",
    "    content = curr_time + ' ' + f'Fold {FOLD}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, valid loss: {(val_loss):.5f}, acc_m: {(acc_m):.6f}, gap_m: {(gap_m):.6f}.'\n",
    "    print(content)\n",
    "    \n",
    "    with open(os.path.join(MODEL_DIR, f'{MODEL_NAME}.txt'), 'a') as appender:\n",
    "        appender.write(content + '\\n')\n",
    "\n",
    "    print('gap_m_max ({:.6f} --> {:.6f}). Saving model ...'.format(gap_m_max, gap_m))\n",
    "    \n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        },\n",
    "        model_file\n",
    "    )\n",
    "    gap_m_max = gap_m\n",
    "\n",
    "print(datetime.strftime(datetime.now(), '%Y%b%d_%HH%MM%SS'), 'Training Finished!')\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, \n",
    "    os.path.join(MODEL_DIR, f'{MODEL_NAME}_fold{FOLD}_final.pth')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
